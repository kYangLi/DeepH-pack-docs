---
name: DeepH-pack 模型训练与超参优化
description: "本指南旨在通过 DeepH-pack 执行系统性的模型训练与批量超参搜索，以挖掘模型性能极限。内容涵盖从计算环境配置、网络架构选择、参数空间定义到自动化批量策略及结果评估的全流程最佳实践，帮助用户高效锁定最优配置，显著提升预测精度。"
license: Proprietary. LICENSE.txt 中包含全部授权信息。
---

# DeepH-pack 模型训练与超参优化指南

## 1. 背景介绍

DeepH-pack 是清华大学 DeepH 团队多年研究成果的集大成者。最新版本基于 JAX 和 Flax 框架重写，集成了先前所有方法，并提供了统一的调用接口。经过对神经网络模块的长期严格测试，DeepH-pack 在用户体验上已高度成熟。

得益于 JAX 的静态计算图和先进算法，当前版本在**运行时性能**、**计算精度**和**内存效率**方面均表现卓越。未来，DeepH-pack 将致力于无缝集成多物理量预测能力，旨在成为一个可扩展的高精度量子材料建模计算平台，确保哈密顿量构建达到量子化学级精度。

## 2. 环境准备与确认

在使用 DeepH-pack 开启训练任务前，请务必确认环境配置正确。

### 2.1 检查安装状态
可以通过检查 Python 环境中是否存在 `deepx` 包来验证安装。DeepH-pack 的安装包命名格式通常为 `deepx_pack-1.2.x-py3-none-any.whl`。

**版本检测代码：**
```python
import deepx
print(f"DeepH-pack version: {deepx.__version__}")
```

若未安装，请参考 [DeepH 安装指南](./deeph_install.md)。

### 2.2 安装辅助工具 DeepH-dock
DeepH-dock (包名：`deepx-dock`) 是 DeepH 训练流程中的重要辅助工具，提供了网络表示推荐（Analysis of Dataset Features）等必要功能。检查deepx-dock包是否安装, 如否，请执行以下命令进行安装。

**安装指令：**
```bash
# 请确保在 DeepH-pack 所在的 uv venv 环境中执行
uv pip install deepx-dock
```

安装完成后，命令行会新增 `dock` 指令，用于调用其内部定义的命令行工具。

## 3. 标准训练流程

### 3.1 配置训练参数 (TOML)
DeepH 使用 TOML 文件进行训练和推理配置。**默认训练配置模版可参考本 skill 文件夹内的CONFIG_TRAIN_DEFAULT.toml**。

**配置文件：**
*   用户配置文件TOML参考模版！：
    *   阅读 CONFIG_TRAIN_DEFAULT.toml 获取：包含默认训练配置模版。
    *   阅读 CONFIG_TRAIN_VALID.toml 获取：训练配置参数值的合法类型或范围。
*   阅读 training_toml.md 获取：训练配置参数的详细定义和补充说明。
*   配置文件名可任意自定义（例如 `my_train.toml`）。

### 3.2 数据集准备

**1. 存储路径与格式**
*   **存放位置**：训练数据须存放于 TOML 配置文件中 `data.inputs_dir` 指定的目录。
*   **格式规范**：数据结构需严格遵循 DeepH 数据集规范，具体定义请参考 dataset_format.md。
*   **路径提示**：配置文件支持相对路径（相对于 TOML 文件所在目录），但为避免解析歧义，**强烈推荐使用绝对路径**。

**2. 网络表示 (Network Representation) 推荐**
*   **功能概述**：DeepH-dock 内置自动化分析模块，可根据数据集特征生成网络表示（Representation）的推荐配置，辅助用户快速构建基准模型。
*   **使用方法**：使用 `dock analyze dataset features` 命令对指定数据集路径进行分析：
    ```bash
    # 注意：若该命令在部分环境下执行失败，可通过设置环境变量或添加 -p 1 参数强制串行执行，以提高稳定性。
    dock analyze dataset features <inputs_dir> # <inputs_dir> 应包含 dft/ 子目录
    ```
*   **重要提示!**：工具生成的配置仅作为初始参考（Baseline）。鉴于网络表示是决定模型精度与收敛性的关键超参数，强烈建议在实际应用中以此为基础，进行多组实验对比（Ablation Study）以确定最优配置。

**3. 数据集划分策略**
可以通过以下两种方式配置数据集的划分：
*   **方式 A：按样本数量划分（基础模式）**
    在 TOML 中配置 `train_size`, `validate_size`, `test_size` 三个**整数参数**，分别指定训练集、验证集和测试集的样本数量。
*   **方式 B：精确指定划分（高级模式）**
    若需精确控制样本分配以保证实验的一致性（Reproducibility），请配置 `dataset_split_json` 选项。
    *   该选项需指向一个包含具体样本 ID 列表的 JSON 文件。
    *   **辅助工具**：可使用 DeepH-dock 指令生成该文件：
        ```bash
        # 注意：若该命令在部分环境下执行失败，可通过设置环境变量或添加 -p 1 参数强制串行执行，以提高稳定性。
        dock analyze dataset split <inputs_dir> # <inputs_dir> 应包含 dft/ 子目录
        ```

### 3.3 任务提交方式

#### A. 裸机环境 (Bare Metal)
直接在终端运行指令即可，建议使用 `nohup ... &` 保持后台运行：
```bash
deeph-train my_train.toml
```

#### B. 超算环境 (HPC with Slurm/PBS)
在超算环境中，**严禁在登录节点直接运行任何高负载任务**。必须通过作业调度系统（如 Slurm, PBS）提交。提交任务前，建议向用户索要提交脚本模板，以快速得知作业提交队列、环境加载等信息。

**特别注意事项！**
1.  **作业命名隔离**：**务必为每一批次作业添加唯一的名称前缀（如随机动物名，`panda_`等）**，以实现同账户下不同实验组的命名空间隔离，防止混淆。
2.  **获取提交模板**：启动作业前，**务必要求用户/管理员提供标准的作业提交模板文件**，以确保准确掌握作业队列、环境加载等关键配置信息。
3.  **资源一致性**：调度系统申请的 GPU 数量必须与 TOML 配置文件中 system.device 的参数严格保持一致。

## 4. 批量测试与调参策略

批量测试旨在通过自动化脚本一次性提交多组实验，以快速筛选最优超参。

### 4.1 自动化流程规范
1.  **资源评估**：依据服务器整体算力与单任务资源需求，决定并发作业量。重点评估单任务显存开销，据此制定单卡并发或多卡并行策略。
2.  **提交策略**：
    *   **裸机环境**：部署守护脚本（Daemon Script）实时监控 GPU 负载，实现基于显存空闲状态的动态任务调度。
    *   **超算环境**：利用作业调度系统批量投递任务。需严格遵守最大排队数限制，并为本批次作业名添加唯一标识前缀（如随机动物名），以实现同账户下不同实验组的命名空间隔离。
3.  **结果汇总**：必须编写一个汇总脚本（Summary Script），用于解析日志并生成报告。报告应包含当前进度、Loss 收敛情况及最优参数组合，以便随时查看。

### 4.2 最佳实践
*   **预测试 (Smoke Test)**：在进行大规模提交之前，建议先运行1-2个小任务进行调试，以确保脚本逻辑的正确性。对于超大规模模型训练（训练单 Epoch 的运行时间超过 30 分钟），可跳过此步骤。
    *   **裸机**：在裸机环境执行预测试时，请务必将命令的超时阈值 (Timeout) 调整为 15 分钟，以确保任务能够顺利完成。
    *   **超算**：在超算集群上进行预测试，**严禁在登录节点直接进行测试**，请务必通过作业提交系统提交测试作业。
*   **环境整洁**：将中间临时文件统一存放或定期清理，避免目录混乱。
*   **进程安全**：批量脚本应具备精确的进程控制能力，**严禁误杀**非当前测试任务的 DeepH 进程。

### 4.3 文件夹结构
作业提交目录的文件结构如下：
```text
.
├── inputs/                  # [输入] 数据文件目录 (用户提供，名称可变)
├── configs/                 # [配置] 批量测试配置文件目录
│   ├── .base_config.toml    #      基础模板配置 (隐藏文件)
│   ├── config001.toml       #      测试任务 1 配置
│   ├── config002.toml       #      测试任务 2 配置
│   └── ...                  #      更多测试任务配置...
├── script/                  # [代码] 功能性脚本目录
├── outputs/                 # [输出] 测试结果产物目录
│   ├── config001/           #      对应 config001 的结果
│   ├── config002/           #      对应 config002 的结果
│   └── ...                  #      更多测试任务输出...
├── logs/                    # [日志] 运行日志 (STDOUT/STDERR/slurm-*.out等)
└── .test/                   # [缓存] 预测试相关文件 (隐藏目录)
```

## 5. 模型调参经验库

以下是 DeepH 团队总结的关键调参经验，分为网络结构、物理设置、优化策略三部分。

### 5.1 网络结构参数
*   **`net_irreps` (关键)**：定义神经网络中间层的 E3 变换表示。此参数直接决定模型的表示能力和参数量。
    *   **必须手动指定**，默认为空是非法的。
    *   **所有Channel数必须大于等于2**，例如`16x0e+4x1e+1x2e`是非法的。
    *   **推荐做法**：使用 `dock analyze dataset features` 工具基于 `dft/` 原始数据分析推荐值。
*   **`num_blocks`**：决定网络深度。
    *   专用模型（单一材料）：3-5 层。
    *   通用模型（跨元素周期表）：5 层以上。
*   **`num_heads`**：注意力头数，通常设为 `2` 即可。
*   **`latent_irreps` / `latent_scalar_dim`**：在使用 `albatross` 等特定网络时非常关键，设置逻辑同 `net_irreps`。
*   **`enable_bs3b_layer` & `bs3b_orbital_types`**：**多化学元素模型必开**。这对提升泛化能力至关重要。其格式为 bs3b_orbital_types = "sNpNdNfN...", 其中s,p,d,f为不同l的轨道类型，N为轨道数。例如`s3p2d1`对应`[0,0,0,1,1,2]`,代表了s轨道3个，p轨道2个，d轨道1个。
*   **`standardize_gauge`**: **非专用模型必开**。对于非专用模型（即不仅仅针对单一结构及其微扰体系进行训练的模型）而言，该设置至关重要，能有效解决不同结构间化学势参考点不一致的问题，确保训练的准确性。

### 5.2 物理与数据设置
*   **`net_type` 核心网络选择**：
    *   哈密顿量/密度矩阵任务：首选 `eagleplus` 或 `albatross`。
*   **`target_type` 预测目标（物理量）**：本 Skill 专为预测**哈密顿量**或**密度矩阵**而设计。对**力场（或原子间势）**等任务提供有限支持，使用时需用户显式定义额外的任务特征。
*   **`loss_type` Loss Function**：
    *   首选：`MAE` (Mean Absolute Error)。
    *   备选：`MSE` 偶尔也可尝试。
*   **`gaussian_basis_rmax`**：必须覆盖哈密顿量基组的半径范围，推荐值为 `7.5 - 10.0`。
*   **`test_size` 测试集规模**：**必须划分测试集**。没有测试集无法评估过拟合情况，模型结果将失去参考意义。

### 5.3 优化器与训练策略
*   **`max_epoch`**： 通常建议设为 `10000` 以上。设置较大的数值旨在确保模型能够充分收敛（即等待学习率衰减至最低阈值），避免因 Epoch 次数耗尽而导致训练过早被强制截断。
*   **`batch_size`**：
    *   晶体材料：通常设为 `1`。
    *   分子体系：建议 `10` 以上。
    *   *注：需根据显存实际情况调整。*
*   **`dropout_rate`**：可尝试 `0.0` 或 `0.1`，观察对过拟合的影响。
*   **`optimizer`**：推荐 `adamw`。初始学习率范围 `1E-2` 至 `1E-4`。
*   **`scheduler` (学习率调度)**：
    *   大模型：推荐 `warmup_cosine_decay`，decay 步数建议 50 万步以上。
    *   专用模型：可尝试 `reduce_on_plateau`。
        *   分子（快速）：patience 设为 100-200。
        *   分子（慢速）：patience 设为 500-1000。
        *   晶体：patience 设为 50-200。
*   **`multi_way_jit_num`**：解决 JAX 静态图导致的编译慢问题。通过将边数分桶加速计算。
    *   通用模型：10-20 桶。
    *   专用模型：1 桶。
    *   *技巧：如果 JIT 时间过长，可开启 `ahead_of_time_compile` 进行并行预编译。*

## 6. 常见问题排查 (FAQ)

### Q1: 作业提交超过10分钟，为何一直卡在“模型建立”阶段？
**A:** 这是正常现象。DeepH 基于 JAX，首次运行时需要进行 **JIT (Just-In-Time)** 编译，该过程可能较为耗时（视模型复杂度而定，10分钟以上属正常范围）。请耐心等待。

### Q2: 遇到显存不足 (OOM) 怎么办？
**A:** 请按以下顺序排查优化：
1.  **检查模型规模**：`net_irreps` 或 `num_blocks` 是否过大？
2.  **降低 Batch Size**：这是最直接的手段。
3.  **多卡并行**：利用节点内多卡并行（DeepH 目前支持节点内多卡，不支持跨节点并行）。

### Q3: 浮点精度 (Float Type) 如何选择？
**A:** 强烈推荐 **FP32**。
*   FP64：速度过慢，通常不必要。
*   TF32/BF16：精度对于科学计算而言通常不足，可能导致训练发散或结果不准。

### Q4: 批量训练时 `data.outputs_dir` 有什么注意事项？
**A:** 虽然系统会自动按时间戳生成子目录，但**强烈建议**为每种测试配置手动指定唯一的 `outputs_dir`。
*   **原因**：防止批量提交速度过快导致时间戳重叠（撞车），造成不同实验输出到同一目录的严重 Bug，同时也便于后续的模型管理和对比。

### Q5: 建图模式 `disk` vs `memory` 如何选择？
**A:** 关于建图模式，推荐优先使用 **Memory 模式**。
*   **Memory 模式**：将图数据全量加载到内存。**速度最快**，推荐内存充足时首选。
*   **Disk 模式**：数据存储在磁盘，随用随读。**节省内存**，但会显著增加 I/O 开销，降低训练速度。仅在内存不足时使用。
